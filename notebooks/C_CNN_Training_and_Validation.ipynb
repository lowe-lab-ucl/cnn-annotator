{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0xrtPBJm1p8"
   },
   "source": [
    "# CNN Training for Cell Cycle State Classification\n",
    "\n",
    "### Welcome!\n",
    "\n",
    "This notebook allows you to train a convolutional neural network (CNN) using your annotated single-cell image patches & make new predictions about the labels of previously unseen images. Follow the step-wise instructions to proceed with the network training and testing of the accuracy. \n",
    "\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "1. You are using the virtual environment of the [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb \"Google Colaboratory\"). To be able to train the neural network on your annotated data, you must first **import your data** into the folders to source from. Please follow the instructions after executing the first cell of this notebook.\n",
    "\n",
    "2. If using Google Colab: This session will 'timeout' if you do not interact with it. It's 90 minutes if you close the browser or 12 hours if you keep the browser open. Additionally, if you close your browser with a code cell is running, if that same cell has not finished, when you reopen the browser it will still be running (the current executing cell keeps running even after browser is closed). Please visit this [StackOverflow](https://stackoverflow.com/questions/54057011/google-colab-session-timeout \"Google Colab Session Timeout\") discussion for more details.\n",
    "\n",
    "\n",
    "### Running Instructions:\n",
    "\n",
    "1. Prior to running the whole notebook in one go, make sure to execute the first cell containing code. This allows to install the CellX library & create local directories in the environment of the virtual machine. The executed first cell will print ```Building wheel for cellx (setup.py) ... done```. \n",
    "\n",
    "2. Click on the ``` ðŸ“``` folder icon located on the left-side dashboard of the Colab notebook. You should now see 4 subfolders in this directory: \"sample_data\" (default), \"logs\" \"train\" and \"test\" folder, which should all be empty.\n",
    "\n",
    "3. At this point, you should **manually move your 'annotation_XXX.zip' files into the \"train\" and \"test\" folders**. Doing so will allow the image patch data to be processed, divided into categories and used for model training & predictions.\n",
    "\n",
    "4. You can now now run the entire notebook by clicking on ```Runtime``` > ```Run all``` in the upper main dashboard. Re-running the initial cell will fail to create the \"logs\" \"train\" and \"test\" folders as those are already in the directory. \n",
    "\n",
    "5. Prior to training of the model, this notebook will distribute the image patch data into the training & testing sets and introduce data augmentations. The notebook will ultimately train the neural network based on the hyperparameters you've set up.\n",
    "\n",
    "6. During training, you can actively visualise what the network is doing via [TensorBoard](https://www.tensorflow.org/tensorboard/get_started \"TensorFlow || Tensorboard\"), a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more.\n",
    "\n",
    "---\n",
    "\n",
    "**Happy training!**\n",
    "\n",
    "*Your [CellX](http://lowe.cs.ucl.ac.uk/cellx.html \"Lowe Lab @ UCL\") team*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q72wbtUm1qD"
   },
   "source": [
    "### Install the CellX library & create subdirectories in the virtual machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOtdYdHfm1qD"
   },
   "outputs": [],
   "source": [
    "# if using colab, install cellx library and make log and data folders\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    try: \n",
    "        import cellx\n",
    "    except:\n",
    "        !pip install -q git+git://github.com/quantumjot/cellx.git\n",
    "        !mkdir logs\n",
    "        !mkdir train\n",
    "        !mkdir test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxGN9I8Tm1qE"
   },
   "source": [
    "### Import libraries and CellX toolkit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI0vgg9jm1qE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSQ2HRVJm1qE"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4FcQHy6m1qE"
   },
   "outputs": [],
   "source": [
    "from cellx.layers import Encoder2D\n",
    "from cellx.tools.dataset import build_dataset\n",
    "from cellx.tools.dataset import write_dataset\n",
    "from cellx.augmentation.utils import append_conditional_augmentation, augmentation_label_handler\n",
    "from cellx.callbacks import tensorboard_confusion_matrix_callback\n",
    "from cellx.tools.io import read_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xc6DAoZ3m1qF"
   },
   "source": [
    "### Define paths & class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rw1ipBL0m1qF"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./train\"\n",
    "TEST_PATH = \"./test\"\n",
    "TRAIN_FILE = os.path.join(TRAIN_PATH, 'CNN_train.tfrecord')\n",
    "TEST_FILE = os.path.join(TEST_PATH, 'CNN_test.tfrecord')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv5QAp3um1qF"
   },
   "source": [
    "### Set-up CNN training hyperparameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-QTgXl7m1qF"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20_000\n",
    "TRAINING_EPOCHS = 100\n",
    "BOUNDARY_AUGMENTATION = True\n",
    "INPUT_SHAPE = (64, 64, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JAxyQQxm1qF"
   },
   "source": [
    "### Load the Tensorboard extension for real-time visualisation of CNN training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PFrffAZm1qF"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "LOG_ROOT = './logs'\n",
    "LOG_DIR = os.path.join(LOG_ROOT, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVvw12DTm1qG"
   },
   "source": [
    "### Generate TensorFlow Record (TFRecord) files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHdOede2m1qG"
   },
   "outputs": [],
   "source": [
    "def create_tf_record(\n",
    "    root: str, \n",
    "    filename: str,\n",
    "    use_flagged: bool = False\n",
    "):\n",
    "\n",
    "    # load the annotations\n",
    "    _images, _labels, _states = read_annotations(root, use_flagged=use_flagged)\n",
    "    images_arr = np.stack(_images, axis=0)[..., np.newaxis]\n",
    "    labels_arr = np.stack(_labels, axis=0)\n",
    "    \n",
    "    # write the tf dataset\n",
    "    write_dataset(filename, images_arr.astype(np.uint8), labels=labels_arr.astype(np.int64))\n",
    "\n",
    "    # return the state labels \n",
    "    states = [k for k, v in sorted(_states.items(), key=lambda item: item[1])]\n",
    "\n",
    "    # plot some stats \n",
    "    stats = {k: _labels.count(v) for k, v in _states.items()}\n",
    "    print(f\"Exported \\'{filename}\\' containing:\")\n",
    "    if not use_flagged: print(f\" - Excluding flagged files\")\n",
    "    for k, v in stats.items():\n",
    "        print(f\" - [{_states[k]}] {k}: {v}\")\n",
    "    print(f\" - Total images: {images_arr.shape[0]}\")\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzgrYn4Mm1qG"
   },
   "source": [
    "## IMPORTANT: \n",
    "\n",
    "**Prior to calling the function to create the TFRecods files:**\n",
    "\n",
    "You need to manually drag the annotation_XXX.zip files into the newly created folders. If you are working in the Google Colab environment, click on the folder icon at the left-side dashboard, which should now contain the 'logs', 'train' and 'test' directories. They should be empty until you drag your annotation files into them.\n",
    "\n",
    "Once the files have been imported, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gjsrmn4Gm1qG"
   },
   "outputs": [],
   "source": [
    "LABELS = create_tf_record(TRAIN_PATH, TRAIN_FILE, use_flagged=not BOUNDARY_AUGMENTATION)\n",
    "_ = create_tf_record(TEST_PATH, TEST_FILE, use_flagged=not BOUNDARY_AUGMENTATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrLhVmunm1qG"
   },
   "source": [
    "### Create a simple CNN for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGgzMUfmm1qG"
   },
   "outputs": [],
   "source": [
    "img = K.layers.Input(shape=INPUT_SHAPE)\n",
    "x = Encoder2D(layers=[8, 16, 32, 64, 128])(img)\n",
    "x = K.layers.Flatten()(x)\n",
    "x = K.layers.Dense(256, activation=\"relu\")(x)\n",
    "x = K.layers.Dropout(0.2)(x)\n",
    "logits = K.layers.Dense(len(LABELS), activation=\"linear\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECXUoYTMm1qG"
   },
   "outputs": [],
   "source": [
    "model = K.Model(inputs=img, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO-zelEnm1qH"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqYuOJzmm1qH"
   },
   "source": [
    "### Set-up some augmentations to be used while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RolEOzdkm1qH"
   },
   "outputs": [],
   "source": [
    "@augmentation_label_handler\n",
    "def normalize(img):\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    # clip to 4 standard deviations\n",
    "    img = tf.clip_by_value(img, -4., 4.)\n",
    "    tf.debugging.check_numerics(img, \"Image contains NaN\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OaAOKscam1qH"
   },
   "outputs": [],
   "source": [
    "@augmentation_label_handler\n",
    "def augment(img):\n",
    "    if BOUNDARY_AUGMENTATION:\n",
    "        # this will randomly simulate the cropping that occurs at the edge of\n",
    "        # an image volume\n",
    "\n",
    "        vignette = np.ones(INPUT_SHAPE, dtype=np.float32)\n",
    "        width = np.random.randint(0,INPUT_SHAPE[0]//2)\n",
    "        vignette[:,:width,...] = 0\n",
    "\n",
    "        img = tf.cond(pred=tf.random.uniform(shape=())<0.05,\n",
    "                true_fn=lambda: tf.multiply(img, vignette),\n",
    "                false_fn=lambda: img)\n",
    "\n",
    "    # do some data augmentation\n",
    "    k = tf.random.uniform(maxval=3, shape=(), dtype=tf.int32)\n",
    "    img = tf.image.rot90(img, k=k)\n",
    "\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eimItukpm1qH"
   },
   "outputs": [],
   "source": [
    "@augmentation_label_handler\n",
    "def random_contrast(x):\n",
    "    return tf.image.random_contrast(x, 0.3, 1.0)\n",
    "\n",
    "@augmentation_label_handler\n",
    "def random_brightness(x):\n",
    "    return tf.image.random_brightness(x, 0.3, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEG82mW7m1qI"
   },
   "source": [
    "### Build the training dataset, with random augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlTndbA_m1qI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = build_dataset(TRAIN_FILE, read_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OoqJyaBym1qI"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(augment)\n",
    "dataset = append_conditional_augmentation(dataset, [random_contrast, random_brightness])\n",
    "dataset = dataset.map(normalize)\n",
    "dataset = dataset.shuffle(buffer_size=BUFFER_SIZE, reshuffle_each_iteration=True)\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn1nSEzzm1qI"
   },
   "source": [
    "### Build the test dataset, without augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECP5UPcQm1qI"
   },
   "outputs": [],
   "source": [
    "test_dataset = build_dataset(TEST_FILE, read_label=True)\n",
    "test_dataset = test_dataset.map(normalize)\n",
    "test_dataset = test_dataset.take(-1).as_numpy_iterator()\n",
    "\n",
    "test_images, test_labels = zip(*list(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jw1y23j8m1qI"
   },
   "source": [
    "### Set up tensorboard callbacks to monitor training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90bpVbU6m1qI"
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = K.callbacks.TensorBoard(log_dir=LOG_DIR)\n",
    "confusion_matrix_callback = tensorboard_confusion_matrix_callback(\n",
    "    model, \n",
    "    np.asarray(test_images), \n",
    "    test_labels,\n",
    "    LOG_DIR,\n",
    "    class_names=LABELS,\n",
    "    is_binary=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCsvx5Wym1qI"
   },
   "source": [
    "### Set up the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-RACBplm1qJ"
   },
   "outputs": [],
   "source": [
    "loss = K.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIh-cxg-m1qJ"
   },
   "source": [
    "## Finally, train the model and evaluate performance using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DswRNnP4m1qJ"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir $LOG_ROOT --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DfOllDim1qJ"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    dataset, \n",
    "    steps_per_epoch=BUFFER_SIZE//BATCH_SIZE, \n",
    "    epochs=TRAINING_EPOCHS, \n",
    "    callbacks=[tensorboard_callback, confusion_matrix_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXXpzausm1qJ"
   },
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCQP5QeRm1qJ"
   },
   "outputs": [],
   "source": [
    "model_name = 'model'\n",
    "model.save('{}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdrkVzYZm1qJ"
   },
   "source": [
    "Do not terminate this notebook before saving the model. To export the saved model to your local machine, press the '...' button next to the `model.h5` file on the left side dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApWKYXRDm1qJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "C_CNN_Training_and_Validation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
